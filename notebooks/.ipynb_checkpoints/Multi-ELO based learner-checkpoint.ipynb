{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/pedroantonio/Desktop/TFG/notebooks/anonamyze_all_data_collection.csv'\n",
    "dataEvents = pd.read_csv(path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'user'\n",
    "student_column_number = 1\n",
    "group_column_number = 0\n",
    "completed = 'n_completed'\n",
    "puzzle_name = 'task_id'\n",
    "puzzle_column_number = 2\n",
    "kc_column = 'kc'\n",
    "kc_column_number = 4\n",
    "\n",
    "kcs = ['GMD.4', 'CO.5', 'CO.6','MG.1']\n",
    "mg1Puzzles = ['Bird Fez', 'Pi Henge', 'Bull Market']\n",
    "gmd4Puzzles = ['Angled Silhouettes', 'Not Bird', 'Stranger Shapes', 'Ramp Up and Can It', 'Few Clues']\n",
    "co5Puzzles = ['45-Degree Rotations', 'Boxes Obscure Spheres', 'More Than Meets the Eye']\n",
    "co6Puzzles = ['Tall and Small', 'Not Bird', 'Ramp Up and Can It', 'Stretch a Ramp', 'Max 2 Boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to positions\n",
    "\n",
    "typeMapping = {'Sandbox': 'GMD.4~CO.5~CO.6', '1. One Box': 'GMD.4~CO.5~CO.6', '2. Separated Boxes': 'GMD.4~CO.5~CO.6', '3. Rotate a Pyramid': 'GMD.4~CO.5~CO.6', '4. Match Silhouettes': 'GMD.4~CO.5~CO.6', '5. Removing Objects': 'GMD.4~CO.5~CO.6', '6. Stretch a Ramp': 'GMD.4~CO.5~CO.6', '7. Max 2 Boxes': 'GMD.4~CO.5~CO.6', '8. Combine 2 Ramps': 'GMD.4~CO.5~CO.6', '9. Scaling Round Objects': 'GMD.4~CO.5~CO.6', \n",
    "               'Square Cross-Sections': 'GMD.4~CO.5~CO.6', 'Bird Fez': 'MG.1~GMD.4~CO.5~CO.6' , 'Pi Henge': 'MG.1~GMD.4~CO.5~CO.6', '45-Degree Rotations': 'GMD.4~CO.5~CO.6',  'Pyramids are Strange': 'GMD.4~CO.5~CO.6', 'Boxes Obscure Spheres': 'GMD.4~CO.5~CO.6', 'Object Limits': 'GMD.4~CO.5~CO.6', 'Tetromino': 'GMD.4~CO.5~CO.6', 'Angled Silhouette': 'GMD.4~CO.5~CO.6',\n",
    "               'Warm Up':'GMD.4~CO.5~CO.6','Sugar Cones': 'GMD.4~CO.5~CO.6', 'Stranger Shapes': 'GMD.4~CO.5~CO.6', 'Tall and Small': 'GMD.4~CO.5~CO.6', 'Ramp Up and Can It': 'GMD.4~CO.5~CO.6', 'More Than Meets Your Eye': 'GMD.4~CO.5~CO.6', 'Not Bird': 'GMD.4~CO.5~CO.6', 'Unnecessary': 'GMD.4~CO.5~CO.6', 'Zzz': 'GMD.4~CO.5~CO.6', 'Bull Market': 'MG.1~GMD.4~CO.5~CO.6', 'Few Clues': 'GMD.4~CO.5~CO.6', 'Orange Dance': 'GMD.4~CO.5~CO.6', 'Bear Market': 'GMD.4~CO.5~CO.6'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adaptedData(dataEvents, group = 'all'):\n",
    "    dataEvents['time'] = pd.to_datetime(dataEvents['time'])\n",
    "    dataEvents = dataEvents.sort_values('time')\n",
    "    \n",
    "    #iterates in the groups and users of the data\n",
    "    dataEvents['group'] = [json.loads(x)['group'] if 'group' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['user'] = [json.loads(x)['user'] if 'user' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['task_id'] = [json.loads(x)['task_id'] if 'task_id' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    \n",
    "    # removing those rows where we dont have a group and a user that is not guest\n",
    "    dataEvents = dataEvents[((dataEvents['group'] != '') & (dataEvents['user'] != '') & (dataEvents['user'] != 'guest'))]\n",
    "    dataEvents['group_user_id'] = dataEvents['group'] + '~' + dataEvents['user']\n",
    "    dataEvents['group_user_task_id'] = dataEvents['group'] + '~' + dataEvents['user']+'~'+dataEvents['task_id']\n",
    "\n",
    "         \n",
    "    # filtering to only take the group passed as argument\n",
    "    if(group != 'all'):\n",
    "        dataEvents = dataEvents[dataEvents['group'].isin(group)]\n",
    "          \n",
    "    # the data is grouped by the necessary variables      \n",
    "    activity_by_user = dataEvents.groupby(['group_user_id','group', 'user','group_user_task_id','task_id']).agg({'id':'count',\n",
    "                                             'type':'nunique'}).reset_index().rename(columns={'id':'events',\n",
    "                                                                                              'type':'different_events'}) \n",
    "    \n",
    "    \n",
    "    #indicate the index variable                                                                                                                                                               \n",
    "    activity_by_user.index = activity_by_user['group_user_task_id'].values\n",
    "                                                                                              \n",
    "    #initialize the metrics          \n",
    "    activity_by_user['active_time'] = np.nan\n",
    "    activity_by_user['n_completed'] = 0\n",
    "    activity_by_user['kc'] = ''\n",
    "    #initialize the data structures\n",
    "    puzzleEvents = dict()\n",
    "    timePuzzle = dict()\n",
    "    puzzCom= dict()\n",
    "    puzzDestr = dict()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for user in dataEvents['group_user_id'].unique():\n",
    "        \n",
    "        # Computing active time\n",
    "        previousEvent = None\n",
    "        theresHoldActivity = 60 # np.percentile(allDifferences, 98) is 10 seconds\n",
    "        activeTime = []\n",
    "        \n",
    "        user_events = dataEvents[dataEvents['group_user_id'] == user]\n",
    "        user_puzzle_key = None\n",
    "\n",
    "        for enum, event in user_events.iterrows():\n",
    "            \n",
    "            if(event['type'] in ['ws-start_level', 'ws-puzzle_started']):\n",
    "                                                                          \n",
    "                user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id']\n",
    "               \n",
    "                # initialize if the id is new                                                                              \n",
    "                if(user_puzzle_key not in puzzleEvents.keys()):\n",
    "                    puzzleEvents[user_puzzle_key]= 1\n",
    "                    timePuzzle[user_puzzle_key] = 0\n",
    "                    puzzCom[user_puzzle_key] = 0\n",
    "                    puzzDestr[user_puzzle_key] = ''\n",
    "                    \n",
    "            # the event is not final event\n",
    "            if(event['type'] not in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-create_user', 'ws-login_user']): \n",
    "                    puzzleEvents[user_puzzle_key] += 1\n",
    "                    splitDes = user_puzzle_key.split(\"~\")\n",
    "                    puzzDestr[user_puzzle_key] = typeMapping[splitDes[2]]                                                                          \n",
    "                    \n",
    "                       \n",
    "                        \n",
    "            # the puzzle ends        \n",
    "            if(event['type'] in ['ws-exit_to_menu', 'ws-puzzle_complete']):\n",
    "                    if(event['type'] in ['ws-puzzle_complete']):\n",
    "                        if(puzzCom[user_puzzle_key] ==0):\n",
    "                            puzzCom[user_puzzle_key] +=1\n",
    "\n",
    "    \n",
    "    \n",
    "    cont = dict()\n",
    "    # add the data by group_user_task_id            \n",
    "    for i in dataEvents['group_user_task_id'].unique():\n",
    "        key_split = i.split('~')\n",
    "        if(key_split[1] not in cont.keys()): cont[key_split[1]] = 0\n",
    "        if(key_split[2] != ''):\n",
    "            activity_by_user.at[i, 'kc'] = puzzDestr[i]\n",
    "            activity_by_user.at[i, 'n_completed'] = puzzCom[i]\n",
    "            activity_by_user.at[i, 'active_time'] = timePuzzle[i]\n",
    "\n",
    "\n",
    "    #delete row with NaN\n",
    "    activity_by_user.dropna(inplace=True)\n",
    "  \n",
    "    #data output preparation             \n",
    "    activity_by_user = pd.DataFrame(activity_by_user, columns = ['group_user_task_id','group','user','task_id', 'n_completed', 'kc'])\n",
    "\n",
    "    train = activity_by_user.head(round(len(activity_by_user)*0.7))\n",
    "    test = activity_by_user.tail(len(activity_by_user) - round(len(activity_by_user)*0.7))\n",
    "    \n",
    "    return activity_by_user, train, test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict users: uDict\n",
    "def usersDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapUsers = {}\n",
    "    mapGroups = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        user = row[1]['user']\n",
    "        group = row[1]['group']\n",
    "        if user not in mapUsers.keys():\n",
    "            mapUsers[user]=cont\n",
    "            mapGroups[user] = group\n",
    "            cont = cont+1\n",
    "    return mapUsers, mapGroups  \n",
    "\n",
    "\n",
    "# Dict puzzles: qDict\n",
    "def puzzlesDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapPuzzles = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        question = row[1]['task_id']\n",
    "        if question not in mapPuzzles.keys():\n",
    "            mapPuzzles[question]=cont\n",
    "            cont = cont+1\n",
    "    return mapPuzzles\n",
    "\n",
    "\n",
    "\n",
    "# Dict kcs: kcDict \n",
    "def kcsDict(datafile):\n",
    "    QT = []\n",
    "    csv_file = datafile\n",
    "    mapKc = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        tags = row[1]['kc'] \n",
    "        if tags:\n",
    "            tag = tags.split(\"~\")\n",
    "            for topics in tag:\n",
    "                if topics not in mapKc.keys():\n",
    "                    mapKc[topics]=cont\n",
    "                    cont = cont + 1\n",
    "    return mapKc\n",
    "\n",
    "def createKcDict(datafile):\n",
    "    \n",
    "    QTMat = dict()\n",
    "    csv_file = datafile\n",
    "    for row in csv_file.iterrows():\n",
    "        qid = row[1]['task_id']\n",
    "        kcs = row[1]['kc']\n",
    "        if(qid not in QTMat.keys()):\n",
    "            QTMat[qid]=dict()\n",
    "        if kcs:\n",
    "            kc = kcs.split(\"~\")\n",
    "            for k in kc:\n",
    "                QTMat[qid][k] =0\n",
    "\n",
    "\n",
    "    for puzzle in QTMat.keys():\n",
    "        tam = len(QTMat[puzzle])\n",
    "        if tam>0:   \n",
    "            if(puzzle in mg1Puzzles):\n",
    "                QTMat[puzzle]['MG.1'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'MG.1'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in gmd4Puzzles): \n",
    "                QTMat[puzzle]['GMD.4'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'GMD.4'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in co5Puzzles): \n",
    "                QTMat[puzzle]['CO.5'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.5'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in co6Puzzles):  \n",
    "                QTMat[puzzle]['CO.6'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.6'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)              \n",
    "            else:\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    QTMat[puzzle][x] = 1/tam\n",
    "    return QTMat\n",
    "\n",
    "\n",
    "def loadDataset(datafile):\n",
    "    uDict, gDict = usersDict(datafile) \n",
    "    qDict =puzzlesDict(datafile)\n",
    "    kcDict =kcsDict(datafile)\n",
    "    kcsPuzzleDict =  createKcDict(datafile) \n",
    "\n",
    "    return uDict, gDict,qDict,kcDict, kcsPuzzleDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiTopic_ELO(inputData, Competency, Diff,groupDiff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    prob_test = dict()\n",
    "    ans_test = dict()  \n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "        alpha_denominator = 0\n",
    "        uid = item[student_id] \n",
    "        qid = item[puzzle_name] \n",
    "        diff = Diff[qid] \n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "        compTotal = np.sum(comp[uid])\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diff)))\n",
    "        if(uid not in prob_test.keys()):\n",
    "            prob_test[uid] = dict()\n",
    "        prob_test[uid][qid]=probability\n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "        \n",
    "        if(uid not in ans_test.keys()):\n",
    "            ans_test[uid] = dict()\n",
    "        ans_test[uid][qid] = correct \n",
    "        \n",
    "        groupDiff[gDict[uid]][qid] = groupDiff[gDict[uid]][qid] + ((gamma)/(1 + beta * q_answered_count)) * (probability - correct)\n",
    "        \n",
    "        Diff[qid] = Diff[qid] + ((gamma)/(1 + beta * q_answered_count)) * (probability - correct)\n",
    "        Q_count[qid] += 1\n",
    "        \n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            c_lambda = Competency[uid][k]\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - diff)))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            u_answered_count = A_count[uid][k]\n",
    "            c = Competency[uid][k] \n",
    "            probability = (1)/(1 + math.exp( -1 * (compTotal - diff)))\n",
    "            \n",
    "            Competency[uid][k] = Competency[uid][k]+kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "            A_count[uid][k] += 1\n",
    "                \n",
    "    return Competency, Diff,groupDiff, A_count , Q_count, prob_test, ans_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, gamma, beta):\n",
    "    \n",
    "    totalData, train_set, test_set = adaptedData(dataEvents)\n",
    "    uDict,gDict,qDict,kcDict,kcsPuzzleDict = loadDataset(totalData)\n",
    "\n",
    "    competency_ELO = pd.DataFrame()\n",
    "    difficulty_ELO = pd.DataFrame()\n",
    "                                                                                              \n",
    "    #initialize the metrics       \n",
    "    difficulty_ELO['group'] = ''\n",
    "    difficulty_ELO['task_id'] = ''\n",
    "    difficulty_ELO['difficulty'] = np.nan\n",
    "    competency_ELO['group'] = ''\n",
    "    competency_ELO['user'] = ''\n",
    "    competency_ELO['kc'] = ''\n",
    "    competency_ELO['competency'] = np.nan\n",
    "    \n",
    "    \n",
    "    \n",
    "    idComplet = dict()\n",
    "    for g in gDict.values():\n",
    "        for u in gDict.keys():\n",
    "            for k in kcs:\n",
    "                iCom = g+'~'+u+'~'+k\n",
    "                idComplet[iCom] = 0\n",
    "    \n",
    "\n",
    "    if model == 'multiTopic':\n",
    "        \n",
    "        group_difficulty = dict()\n",
    "        question_difficulty = dict() \n",
    "        question_counter = dict() \n",
    "        concatedGroupTask = dict()\n",
    "        for g in gDict.values():\n",
    "            group_difficulty[g] = dict()\n",
    "            for q in qDict.keys():\n",
    "                question_difficulty[q]=0\n",
    "                question_counter[q]=0\n",
    "                group_difficulty[g][q]=0\n",
    "                concatedGroupTask[g+'~'+q] = 0\n",
    "        \n",
    "        \n",
    "        learner_competency = dict()  \n",
    "        response_counter = dict() \n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency.keys()):\n",
    "                learner_competency[user]=dict()\n",
    "                response_counter[user]=dict()\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency[user][k]=0\n",
    "                response_counter[user][k]=0\n",
    "\n",
    "\n",
    "        learner_competency_train, question_difficulty_train,group_difficulty_train, response_counter_train, question_counter_train, prob_train, ans_train   = multiTopic_ELO(train_set, learner_competency, question_difficulty,group_difficulty, response_counter, question_counter, kcsPuzzleDict,gDict,gamma, beta)\n",
    "        learner_competency_test, question_difficulty_test,group_difficulty_test, response_counter_test, question_counter_test, prob_test, ans_test   = multiTopic_ELO(test_set, learner_competency_train, question_difficulty_train,group_difficulty_train, response_counter_train, question_counter_train, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "    totalCompetencyGMD = []\n",
    "    totalCompetencyCO5 = []\n",
    "    totalCompetencyCO6 = []\n",
    "    totalCompetencyMG1 = []\n",
    "\n",
    "    \n",
    "    for user in learner_competency.keys():\n",
    "        for x in learner_competency[user]:\n",
    "            if(x == 'GMD.4'):\n",
    "                totalCompetencyGMD.append(learner_competency[user][x])\n",
    "            elif(x == 'CO.5'):\n",
    "                totalCompetencyCO5.append(learner_competency[user][x]) \n",
    "            elif(x == 'CO.6'):\n",
    "                totalCompetencyCO6.append(learner_competency[user][x])\n",
    "            elif(x == 'MG.1'):\n",
    "                totalCompetencyMG1.append(learner_competency[user][x])    \n",
    "    \n",
    "\n",
    "    minCompetencyGMD = min(totalCompetencyGMD)   \n",
    "    maxCompetencyGMD = max(totalCompetencyGMD)\n",
    "    \n",
    "    minCompetencyCO5 = min(totalCompetencyCO5)   \n",
    "    maxCompetencyCO5 = max(totalCompetencyCO5)\n",
    "    \n",
    "    minCompetencyCO6 = min(totalCompetencyCO6)   \n",
    "    maxCompetencyCO6 = max(totalCompetencyCO6)\n",
    "    \n",
    "    minCompetencyMG1 = min(totalCompetencyMG1)   \n",
    "    maxCompetencyMG1 = max(totalCompetencyMG1)\n",
    "    \n",
    "    normalized_learner_competency = dict()\n",
    "    for user in learner_competency.keys():\n",
    "        normalized_learner_competency[user]=dict()\n",
    "        for x in learner_competency[user]:\n",
    "            if(x == 'GMD.4'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyGMD)/(maxCompetencyGMD-minCompetencyGMD)\n",
    "            elif(x == 'CO.5'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO5)/(maxCompetencyCO5-minCompetencyCO5) \n",
    "            elif(x == 'CO.6'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO6)/(maxCompetencyCO6-minCompetencyCO6)\n",
    "            elif(x == 'MG.1'):\n",
    "                normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyMG1)/(maxCompetencyMG1-minCompetencyMG1)\n",
    "            \n",
    "    \n",
    "    \n",
    "    normalized_question_difficulty = dict()\n",
    "    for puzzle in question_difficulty.keys():\n",
    "        if(puzzle not in question_difficulty.keys()):\n",
    "            normalized_question_difficulty[puzzle] = 0\n",
    "        normalized_question_difficulty[puzzle] = (question_difficulty[puzzle]-min(question_difficulty.values()))/(max(question_difficulty.values())-min(question_difficulty.values()))\n",
    "        \n",
    "\n",
    "    normalized_group_difficulty = dict()\n",
    "    for group in group_difficulty.keys():\n",
    "        normalized_group_difficulty[group] = dict()\n",
    "        for puzzle in group_difficulty[group].keys():\n",
    "            normalized_group_difficulty[group][puzzle]=0\n",
    "            normalized_group_difficulty[group][puzzle] = (group_difficulty[group][puzzle]-min(group_difficulty[group].values()))/(max(group_difficulty[group].values())-min(group_difficulty[group].values()))\n",
    "       \n",
    "            \n",
    "    groupUser = set()\n",
    "    \n",
    "    for i in concatedGroupTask.keys():\n",
    "        key_split = i.split('~')\n",
    "        difficulty_ELO.at[i, 'group'] = key_split[0]\n",
    "        difficulty_ELO.at[i, 'task_id'] = key_split[1]\n",
    "        difficulty_ELO.at[i, 'difficulty'] = normalized_group_difficulty[key_split[0]][key_split[1]]\n",
    "            \n",
    "    for i in idComplet.keys():\n",
    "        key_split = i.split('~')\n",
    "        competency_ELO.at[i, 'group'] = key_split[0]    \n",
    "        competency_ELO.at[i, 'user'] = key_split[1]    \n",
    "        competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "        competency_ELO.at[i, 'competency'] = normalized_learner_competency[key_split[1]][key_split[2]]\n",
    "            \n",
    "  \n",
    "    #data output preparation  \n",
    "    difficulty_ELO = pd.DataFrame(difficulty_ELO, columns = ['group','task_id', 'difficulty'])\n",
    "    competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','kc', 'competency'])\n",
    "\n",
    "    return difficulty_ELO, competency_ELO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty_ELO, competency_ELO = run('multiTopic',1.8, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
