{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import statistics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/pedroantonio/Desktop/TFG/notebooks/anonamyze_all_data_collection.csv'\n",
    "dataEvents = pd.read_csv(path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'user'\n",
    "timestamp = 'initial timestamp'\n",
    "student_column_number = 1\n",
    "group_column_number = 0\n",
    "completed = 'n_completed'\n",
    "puzzle_name = 'task_id'\n",
    "puzzle_column_number = 2\n",
    "kc_column = 'kc'\n",
    "kc_column_number = 4\n",
    "\n",
    "kcs = ['GMD.4', 'CO.5', 'CO.6','MG.1']\n",
    "mg1Puzzles = ['Bird Fez', 'Pi Henge', 'Bull Market']\n",
    "gmd4Puzzles = ['Angled Silhouettes', 'Not Bird', 'Stranger Shapes', 'Ramp Up and Can It', 'Few Clues']\n",
    "co5Puzzles = ['45-Degree Rotations', 'Boxes Obscure Spheres', 'More Than Meets the Eye']\n",
    "co6Puzzles = ['Tall and Small', 'Not Bird', 'Ramp Up and Can It', 'Stretch a Ramp', 'Max 2 Boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeMappingDifficulty = ['Sandbox~SAND', '1. One Box~Tutorial', '2. Separated Boxes~Tutorial', '3. Rotate a Pyramid~Tutorial', '4. Match Silhouettes~Tutorial', '5. Removing Objects~Tutorial', '6. Stretch a Ramp~Tutorial', '7. Max 2 Boxes~Tutorial', '8. Combine 2 Ramps~Tutorial', '9. Scaling Round Objects~Tutorial', \n",
    "               'Square Cross-Sections~Easy Puzzles', 'Bird Fez~Easy Puzzles', 'Pi Henge~Easy Puzzles', '45-Degree Rotations~Easy Puzzles',  'Pyramids are Strange~Easy Puzzles', 'Boxes Obscure Spheres~Easy Puzzles', 'Object Limits~Easy Puzzles', 'Not Bird~Easy Puzzles', 'Angled Silhouette~Easy Puzzles',\n",
    "               'Warm Up~Hard Puzzles','Tetromino~Hard Puzzles', 'Stranger Shapes~Hard Puzzles', 'Sugar Cones~Hard Puzzles', 'Tall and Small~Hard Puzzles', 'Ramp Up and Can It~Hard Puzzles', 'More Than Meets Your Eye~Hard Puzzles', 'Unnecessary~Hard Puzzles', 'Zzz~Hard Puzzles', 'Bull Market~Hard Puzzles', 'Few Clues~Hard Puzzles', 'Orange Dance~Hard Puzzles', 'Bear Market~Hard Puzzles']\n",
    "\n",
    "tutorialPuzzles = []\n",
    "\n",
    "for puzzle in typeMappingDifficulty:\n",
    "    desc = puzzle.split(\"~\")\n",
    "    if(desc[1] == 'Tutorial'):\n",
    "        tutorialPuzzles.append(desc[0])\n",
    "        \n",
    "advancedPuzzles = []\n",
    "\n",
    "for puzzle in typeMappingDifficulty:\n",
    "    desc = puzzle.split(\"~\")\n",
    "    if(desc[1] == 'Hard Puzzles'):\n",
    "        advancedPuzzles.append(desc[0])\n",
    "        \n",
    "        \n",
    "intermediatePuzzles = []\n",
    "\n",
    "for puzzle in typeMappingDifficulty:\n",
    "    desc = puzzle.split(\"~\")\n",
    "    if(desc[1] == 'Easy Puzzles'):\n",
    "        intermediatePuzzles.append(desc[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to positions\n",
    "\n",
    "typeMappingKC = {'Sandbox': 'GMD.4~CO.5~CO.6', '1. One Box': 'GMD.4~CO.5~CO.6', '2. Separated Boxes': 'GMD.4~CO.5~CO.6', '3. Rotate a Pyramid': 'GMD.4~CO.5~CO.6', '4. Match Silhouettes': 'GMD.4~CO.5~CO.6', '5. Removing Objects': 'GMD.4~CO.5~CO.6', '6. Stretch a Ramp': 'GMD.4~CO.5~CO.6', '7. Max 2 Boxes': 'GMD.4~CO.5~CO.6', '8. Combine 2 Ramps': 'GMD.4~CO.5~CO.6', '9. Scaling Round Objects': 'GMD.4~CO.5~CO.6', \n",
    "               'Square Cross-Sections': 'GMD.4~CO.5~CO.6', 'Bird Fez': 'MG.1~GMD.4~CO.5~CO.6' , 'Pi Henge': 'MG.1~GMD.4~CO.5~CO.6', '45-Degree Rotations': 'GMD.4~CO.5~CO.6',  'Pyramids are Strange': 'GMD.4~CO.5~CO.6', 'Boxes Obscure Spheres': 'GMD.4~CO.5~CO.6', 'Object Limits': 'GMD.4~CO.5~CO.6', 'Tetromino': 'GMD.4~CO.5~CO.6', 'Angled Silhouette': 'GMD.4~CO.5~CO.6',\n",
    "               'Warm Up':'GMD.4~CO.5~CO.6','Sugar Cones': 'GMD.4~CO.5~CO.6', 'Stranger Shapes': 'GMD.4~CO.5~CO.6', 'Tall and Small': 'GMD.4~CO.5~CO.6', 'Ramp Up and Can It': 'GMD.4~CO.5~CO.6', 'More Than Meets Your Eye': 'GMD.4~CO.5~CO.6', 'Not Bird': 'GMD.4~CO.5~CO.6', 'Unnecessary': 'GMD.4~CO.5~CO.6', 'Zzz': 'GMD.4~CO.5~CO.6', 'Bull Market': 'MG.1~GMD.4~CO.5~CO.6', 'Few Clues': 'GMD.4~CO.5~CO.6', 'Orange Dance': 'GMD.4~CO.5~CO.6', 'Bear Market': 'GMD.4~CO.5~CO.6'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adaptedData(dataEvents, group = 'all'):\n",
    "    dataEvents['time'] = pd.to_datetime(dataEvents['time'])\n",
    "    dataEvents = dataEvents.sort_values('time')\n",
    "    \n",
    "    #iterates in the groups and users of the data\n",
    "    dataEvents['group'] = [json.loads(x)['group'] if 'group' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['user'] = [json.loads(x)['user'] if 'user' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['task_id'] = [json.loads(x)['task_id'] if 'task_id' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    \n",
    "    # removing those rows where we dont have a group and a user that is not guest\n",
    "    dataEvents = dataEvents[((dataEvents['group'] != '') & (dataEvents['user'] != '') & (dataEvents['user'] != 'guest'))]\n",
    "    dataEvents['group_user_id'] = dataEvents['group'] + '~' + dataEvents['user']\n",
    "    dataEvents['group_user_task_id'] = dataEvents['group'] + '~' + dataEvents['user']+'~'+dataEvents['task_id']\n",
    "\n",
    "         \n",
    "    # filtering to only take the group passed as argument\n",
    "          \n",
    "    activity_by_user = dataEvents.groupby(['group_user_id']).agg({'id':'count',\n",
    "                                             'type':'nunique'}).reset_index().rename(columns={'id':'events',\n",
    "                                                                                              'type':'different_events'}) \n",
    "    \n",
    "    \n",
    "                                                                                              \n",
    "    #initialize the metrics          \n",
    "    activity_by_user['active_time'] = np.nan\n",
    "    activity_by_user['n_completed'] = 0\n",
    "    activity_by_user['kc'] = ''\n",
    "    #initialize the data structures\n",
    "    puzzleEvents = dict()\n",
    "    timePuzzle = dict()\n",
    "    puzzCom= dict()\n",
    "    puzzDestr = dict()\n",
    "    initialTime = dict()\n",
    "    \n",
    "    n_attempts = dict()\n",
    "    attData = dict()\n",
    "    \n",
    "    userPuzzleInit = dict()\n",
    "    n_attemptsAux = dict()\n",
    "    \n",
    "    userTrain = set()\n",
    "    userTest = set()\n",
    "    userTotal = set()\n",
    "    \n",
    "    \n",
    "    for user in dataEvents['group_user_id'].unique():\n",
    "        \n",
    "        # Computing active time\n",
    "        previousEvent = None\n",
    "        theresHoldActivity = 60 # np.percentile(allDifferences, 98) is 10 seconds\n",
    "        activeTime = []\n",
    "        \n",
    "        user_events = dataEvents[dataEvents['group_user_id'] == user]\n",
    "        user_puzzle_key = None\n",
    "\n",
    "        for enum, event in user_events.iterrows():\n",
    "            \n",
    "            if(event['type'] in ['ws-start_level', 'ws-puzzle_started']):\n",
    "                \n",
    "                if(json.loads(event['data'])['task_id'] == 'Sandbox'): continue\n",
    "                \n",
    "                partialKey = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id']\n",
    "                \n",
    "                if(event['user'] not in userTotal):\n",
    "                    userTotal.add(event['user'])\n",
    "\n",
    "                \n",
    "                if(partialKey not in n_attemptsAux.keys()): \n",
    "                    n_attemptsAux[partialKey] = 0\n",
    "                    puzzCom[partialKey] = 0\n",
    "                    \n",
    "                    \n",
    "                if(partialKey not in userPuzzleInit.keys()): \n",
    "                    \n",
    "                    n_attempts[partialKey] = 1\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    userPuzzleInit[partialKey] = 1\n",
    "                    \n",
    "                else: \n",
    "                    \n",
    "                    n_attempts[partialKey] += 1\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    \n",
    "            \n",
    "                # initialize if the id is new                                                                              \n",
    "                if(user_puzzle_key not in puzzleEvents.keys()):\n",
    "                    attData[user_puzzle_key] = {'att': 0, 'completed': 0,'dataCompleted': 0, 'accept': 0, 'timestamp': event['time'], 'repeat':0}\n",
    "                    puzzleEvents[user_puzzle_key]= 1\n",
    "                    timePuzzle[user_puzzle_key] = 0\n",
    "                    puzzDestr[user_puzzle_key] = ''\n",
    "                    initialTime[user_puzzle_key] = 0\n",
    "                                        \n",
    "                    \n",
    "                if(event['type'] in ['ws-puzzle_started']): \n",
    "                    attData[user_puzzle_key]['timestamp'] = event['time']\n",
    "                    \n",
    "            # the event is not final event\n",
    "            if(event['type'] not in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-create_user', 'ws-login_user']): \n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    puzzleEvents[user_puzzle_key] += 1\n",
    "                    splitDes = user_puzzle_key.split(\"~\")\n",
    "                    puzzDestr[user_puzzle_key] = typeMappingKC[splitDes[2]]                                                                          \n",
    "                    if(event['type'] == 'ws-check_solution'):\n",
    "                        attData[user_puzzle_key]['accept'] = 1\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        \n",
    "            # the puzzle ends        \n",
    "            if(event['type'] in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-disconnect']):\n",
    "                \n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    #the data is consistent\n",
    "                    attData[user_puzzle_key]['dataCompleted'] += 1\n",
    "                    #the data is valid\n",
    "                    if(attData[user_puzzle_key]['accept'] == 1 and attData[user_puzzle_key]['dataCompleted']==1):\n",
    "                        n_attemptsAux[partialKey]+=1\n",
    "                        attData[user_puzzle_key]['att'] = n_attemptsAux[partialKey]\n",
    "                        #attempt after solving\n",
    "                        if(event['type'] in ['ws-puzzle_complete']):\n",
    "                            if(puzzCom[partialKey] !=0 and n_attemptsAux[partialKey] > 1):\n",
    "                                attData[user_puzzle_key]['repeat'] = 1\n",
    "                    \n",
    "                    if(event['type'] in ['ws-puzzle_complete']):\n",
    "                        if(puzzCom[partialKey] ==0):\n",
    "                            attData[user_puzzle_key]['completed'] = 1\n",
    "                            if(attData[user_puzzle_key]['accept'] == 1):\n",
    "                                puzzCom[partialKey] +=1\n",
    "\n",
    "                    \n",
    "    \n",
    "    \n",
    "    # add the data by group_user_task_id            \n",
    "    for i in attData.keys(): \n",
    "        key_split = i.split('~')            \n",
    "            \n",
    "        if(len(userTrain) < round(len(userTotal)*0.7)):\n",
    "            userTrain.add(key_split[1])\n",
    "        else: \n",
    "            if(key_split[1] not in userTrain): userTest.add(key_split[1]) \n",
    "                \n",
    "                \n",
    "        \n",
    "        if(key_split[2] != '' and key_split[2] != 'Sandbox' and key_split[3] != '' and i != '' and key_split[1] != ''):\n",
    "            if(attData[i]['accept'] != 0 and attData[i]['dataCompleted'] != 0 and attData[i]['repeat'] == 0):\n",
    "               \n",
    "                # data output preparation\n",
    "                activity_by_user.at[i, 'group_user_task_att'] = key_split[0] + '~' + key_split[1] + '~' + key_split[2] + '~' + str(attData[i]['att'])\n",
    "                activity_by_user.at[i, 'group'] = key_split[0]\n",
    "                activity_by_user.at[i, 'user'] = key_split[1]\n",
    "                activity_by_user.at[i, 'task_id'] = key_split[2]\n",
    "                activity_by_user.at[i, 'attempt'] = attData[i]['att']\n",
    "                activity_by_user.at[i, 'repeat'] = attData[i]['repeat']\n",
    "                activity_by_user.at[i, 'kc'] = puzzDestr[i]\n",
    "                activity_by_user.at[i, 'n_completed'] = attData[i]['completed']\n",
    "                activity_by_user.at[i, 'initial timestamp'] = attData[i]['timestamp']\n",
    "\n",
    "    \n",
    "    #delete row with NaN\n",
    "    activity_by_user.dropna(subset = ['user'], inplace=True)\n",
    "  \n",
    "    #data output preparation             \n",
    "    activity_by_user = pd.DataFrame(activity_by_user, columns = ['group_user_task_att', 'group','user','task_id','n_completed', 'kc', 'initial timestamp'])\n",
    "\n",
    "\n",
    "    train = activity_by_user[activity_by_user['user'].isin(userTrain)]\n",
    "    test = activity_by_user[activity_by_user['user'].isin(userTest)]\n",
    "    \n",
    "    return activity_by_user, train, test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict users: uDict\n",
    "def usersDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapUsers = {}\n",
    "    mapGroups = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        user = row[1]['user']\n",
    "        group = row[1]['group']\n",
    "        if user not in mapUsers.keys():\n",
    "            mapUsers[user]=cont\n",
    "            mapGroups[user] = group\n",
    "            cont = cont+1\n",
    "    return mapUsers, mapGroups  \n",
    "\n",
    "\n",
    "# Dict puzzles: qDict\n",
    "def puzzlesDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapPuzzles = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        question = row[1]['task_id']\n",
    "        if question not in mapPuzzles.keys():\n",
    "            mapPuzzles[question]=cont\n",
    "            cont = cont+1\n",
    "    return mapPuzzles\n",
    "\n",
    "\n",
    "\n",
    "# Dict kcs: kcDict \n",
    "def kcsDict(datafile):\n",
    "    QT = []\n",
    "    csv_file = datafile\n",
    "    mapKc = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        tags = row[1]['kc'] \n",
    "        if tags:\n",
    "            tag = tags.split(\"~\")\n",
    "            for topics in tag:\n",
    "                if topics not in mapKc.keys():\n",
    "                    mapKc[topics]=cont\n",
    "                    cont = cont + 1\n",
    "    return mapKc\n",
    "\n",
    "def createKcDict(datafile):\n",
    "    \n",
    "    QTMat = dict()\n",
    "    csv_file = datafile\n",
    "    for row in csv_file.iterrows():\n",
    "        qid = row[1]['task_id']\n",
    "        kcs = row[1]['kc']\n",
    "        if(qid not in QTMat.keys()):\n",
    "            QTMat[qid]=dict()\n",
    "        if kcs:\n",
    "            kc = kcs.split(\"~\")\n",
    "            for k in kc:\n",
    "                QTMat[qid][k] =0\n",
    "\n",
    "\n",
    "    for puzzle in QTMat.keys():\n",
    "        tam = len(QTMat[puzzle])\n",
    "        if tam>0:   \n",
    "            if(puzzle in mg1Puzzles):\n",
    "                QTMat[puzzle]['MG.1'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'MG.1'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in gmd4Puzzles): \n",
    "                QTMat[puzzle]['GMD.4'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'GMD.4'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in co5Puzzles): \n",
    "                QTMat[puzzle]['CO.5'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.5'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in co6Puzzles):  \n",
    "                QTMat[puzzle]['CO.6'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.6'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)              \n",
    "            else:\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    QTMat[puzzle][x] = 1/tam\n",
    "    return QTMat\n",
    "\n",
    "\n",
    "def loadDataset(datafile):\n",
    "    uDict, gDict = usersDict(datafile) \n",
    "    qDict =puzzlesDict(datafile)\n",
    "    kcDict =kcsDict(datafile)\n",
    "    kcsPuzzleDict =  createKcDict(datafile) \n",
    "\n",
    "    return uDict, gDict,qDict,kcDict, kcsPuzzleDict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmseFunction(prob, ans, lenProb):\n",
    "    prob = np.array(prob)\n",
    "    ground = np.array(ans)\n",
    "    error = (prob - ans) \n",
    "    err_sqr = error*error\n",
    "    rmse = math.sqrt(err_sqr.sum()/lenProb)\n",
    "    return rmse  \n",
    "\n",
    "\n",
    "\n",
    "def accuracyFunction(ans, prob): \n",
    "    ans = np.array(ans)\n",
    "    prob = np.array(prob)\n",
    "    prob[prob >= 0.5] = 1\n",
    "    prob[prob < 0.5] = 0\n",
    "    acc = metrics.accuracy_score(ans, prob)\n",
    "    return acc\n",
    "\n",
    "def get_cohenKappa(y, pred):\n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    pred[pred >= 0.5] = 1\n",
    "    pred[pred < 0.5] = 0\n",
    "    cohenKappa = metrics.cohen_kappa_score(y, pred, labels=None, weights=None, sample_weight=None)\n",
    "    return cohenKappa\n",
    "\n",
    "def auc_roc(y, pred): \n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr) \n",
    "    return auc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_PCA(array):\n",
    "    minPCA = round(np.nanmin(array),3)\n",
    "    maxPCA = round(np.nanmax(array),3) \n",
    "    array2=[]\n",
    "    for i in range(len(array)):\n",
    "        array2.append((array[i] - minPCA) / (maxPCA-minPCA))\n",
    "        \n",
    "    return array2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First stage function: difficulty\n",
    "def arrayDifficulty(inputData, Competency, Diff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    \n",
    "    arrayDiff = dict()\n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "            \n",
    "        alpha_denominator = 0\n",
    "        uid = item[student_id] \n",
    "        qid = item[puzzle_name] \n",
    "        \n",
    "        ## NEW ##\n",
    "        if(qid not in arrayDiff.keys()): arrayDiff[qid] = dict()        \n",
    "        \n",
    "        diff = dict()\n",
    "        diff[qid]=[]\n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        \n",
    "        # The student's current competence by component is multiplied by each component of the question he or she is facing. \n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "            diff[qid].append(Diff[qid][k] * kcsPuzzleDict[qid][k])\n",
    "            \n",
    "        # Adding up the competencies per component to obtain the global competence    \n",
    "        compTotal = np.sum(comp[uid])\n",
    "        diffTotal = np.sum(diff[qid])\n",
    "        \n",
    "        \n",
    "        # With the global competition and the difficulty of the question, the probability of solving it is calculated\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diffTotal)))\n",
    "        \n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        # The puzzle is completed or no\n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "        \n",
    "\n",
    "        #Alpha component is calculated (normalization factor)\n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            c_lambda = Competency[uid][k]\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - Diff[qid][k])))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        \n",
    "        Q_count[qid] += 1\n",
    "        A_count[uid] += 1\n",
    "        \n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            \n",
    "            u_answered_count = A_count[uid]\n",
    "            prevDiff = Diff[qid][k]\n",
    "                        \n",
    "            # Competency probability is calculated\n",
    "            probability = (1)/(1 + math.exp( -1 * (Competency[uid][k] - prevDiff)))\n",
    "            \n",
    "            # Update the difficulty\n",
    "            changeDiff = ((gamma)/(1 + beta * q_answered_count)) *alpha* (probability - correct)\n",
    "            Diff[qid][k] = Diff[qid][k] + kcsPuzzleDict[qid][k] * changeDiff\n",
    "            # Add difficulty\n",
    "            if(k not in arrayDiff[qid].keys()): arrayDiff[qid][k] = []\n",
    "            arrayDiff[qid][k].append(Diff[qid][k])\n",
    "            \n",
    "            # Update the competency                    \n",
    "            changeComp = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability) \n",
    "            Competency[uid][k] = Competency[uid][k]+changeComp\n",
    "                            \n",
    "                \n",
    "    return arrayDiff\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELO algorithm with static difficulty\n",
    "def multiTopic_ELO(inputData, Competency, Diff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    prob_test = dict()\n",
    "    ans_test = dict()  \n",
    "    probUser = dict()\n",
    "    competencyPartial = dict()\n",
    "    userPuzzles = dict()\n",
    "    completedPartialData = dict()\n",
    "    \n",
    "    failAtt = dict()\n",
    "    \n",
    "    probUserTest = dict()\n",
    "    ansUserTest = dict()\n",
    "    \n",
    "    contPuzzlesUser = dict()\n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "            \n",
    "        alpha_denominator = 0\n",
    "        uid = item[student_id] \n",
    "        qid = item[puzzle_name] \n",
    "        time = item[timestamp]\n",
    "        \n",
    "        if(uid not in failAtt.keys()):\n",
    "            failAtt[uid]= dict()\n",
    "        if(qid not in failAtt[uid].keys()):\n",
    "            failAtt[uid][qid] = 0\n",
    "        \n",
    "        if(uid not in userPuzzles.keys()): userPuzzles[uid] = []\n",
    "        userPuzzles[uid].append(qid)\n",
    "        \n",
    "        # Cont the puzzles per user (intermediate and advanced)\n",
    "        if(uid not in contPuzzlesUser.keys()):\n",
    "            contPuzzlesUser[uid] = set()\n",
    "        if(qid in intermediatePuzzles or qid in advancedPuzzles):    \n",
    "            contPuzzlesUser[uid].add(qid)    \n",
    "        \n",
    "        diff = dict()\n",
    "        diff[qid]=[]\n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        \n",
    "        # The student's current competence by component is multiplied by each component of the question he or she is facing. \n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "            diff[qid].append(Diff[qid][k] * kcsPuzzleDict[qid][k])\n",
    "            \n",
    "        # Adding up the competencies per component to obtain the global competence    \n",
    "        compTotal = np.sum(comp[uid])\n",
    "        diffTotal = np.sum(diff[qid])\n",
    "        \n",
    "        # With the global competition and the difficulty of the question, the probability of solving it is calculated\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diffTotal)))\n",
    "        \n",
    "        if(uid not in prob_test.keys()):\n",
    "            prob_test[uid] = dict()\n",
    "            \n",
    "        if(uid not in probUserTest.keys()):\n",
    "            probUserTest[uid] = []\n",
    "            \n",
    "        if(uid not in ansUserTest.keys()):\n",
    "            ansUserTest[uid] = []    \n",
    "        \n",
    "        # Save the probabilities\n",
    "        prob_test[uid][qid]=probability\n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        if(qid in intermediatePuzzles or qid in advancedPuzzles):\n",
    "            probUserTest[uid].append(probability)\n",
    "        \n",
    "        # The puzzle is completed or no\n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "            failAtt[uid][qid] +=1\n",
    "        \n",
    "        if(uid not in ans_test.keys()):\n",
    "            ans_test[uid] = dict()\n",
    "            \n",
    "        # Save the real result    \n",
    "        ans_test[uid][qid] = correct\n",
    "        if(qid in intermediatePuzzles or qid in advancedPuzzles):\n",
    "            ansUserTest[uid].append(correct)\n",
    "\n",
    "        #Alpha component is calculated (normalization factor)\n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            c_lambda = Competency[uid][k]\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - Diff[qid][k])))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        # Initialize new data\n",
    "        if(uid not in probUser.keys()):\n",
    "            probUser[uid] = dict()\n",
    "            competencyPartial[uid] = dict()\n",
    "        \n",
    "        probUser[uid][qid]= probability\n",
    "        \n",
    "        Q_count[qid] += 1\n",
    "        A_count[uid] += 1\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            \n",
    "            u_answered_count = A_count[uid]\n",
    "            c = Competency[uid][k] \n",
    "            prevDiff = Diff[qid][k]\n",
    "            \n",
    "            key = uid+'~'+qid+'~'+k+'~'+str(round(Competency[uid][k],3)) + '~'+str(round(prevDiff,3))\n",
    "            \n",
    "            # Competency probability is calculated\n",
    "            probability = (1)/(1 + math.exp( -1 * (Competency[uid][k] - prevDiff)))\n",
    "            \n",
    "            # Update the difficulty\n",
    "            #changeDiff = ((gamma)/(1 + beta * q_answered_count)) *alpha* (probability - correct)\n",
    "            #Diff[qid][k] = Diff[qid][k] + kcsPuzzleDict[qid][k] * changeDiff\n",
    "            \n",
    "            # Update the competency\n",
    "            # if puzzle is in tutorial puzzles, we do not update the competency\n",
    "            weightAtt = 0\n",
    "            if(qid not in tutorialPuzzles and correct ==1):\n",
    "                # Fail limit\n",
    "                if(failAtt[uid][qid] >= 5): failAtt[uid][qid] == 5\n",
    "                    \n",
    "                weightAtt = (1-(failAtt[uid][qid]/10))\n",
    "                complete_change = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "                changeComp = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability) * weightAtt \n",
    "                Competency[uid][k] = Competency[uid][k]+changeComp\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                changeComp = 0\n",
    "                complete_change = 0\n",
    "                \n",
    "            # Save the new data\n",
    "            completedPartialData[key] = {'prob': 0, 'kcs importance': 0, 'correct': -1, 'Difficulty': 0, 'Group Difficulty': 0, 'update competency': 0}\n",
    "            completedPartialData[key]['prob'] = probability\n",
    "            completedPartialData[key]['kcs importance'] = kcsPuzzleDict[qid][k]\n",
    "            completedPartialData[key]['correct'] = correct\n",
    "            completedPartialData[key]['Difficulty'] = round(Diff[qid][k],3)\n",
    "            completedPartialData[key]['Weight'] = weightAtt\n",
    "            completedPartialData[key]['cont_puzzles'] = len(contPuzzlesUser[uid])\n",
    "            completedPartialData[key]['timestamp'] = time\n",
    "            completedPartialData[key]['changeComp'] = changeComp\n",
    "            completedPartialData[key]['complete_change_comp'] = complete_change\n",
    "            #completedPartialData[key]['changeDiff'] = kcsPuzzleDict[qid][k] * changeDiff\n",
    "            \n",
    "            if(k not in competencyPartial[uid].keys()): competencyPartial[uid][k] = []\n",
    "            competencyPartial[uid][k].append(Competency[uid][k])\n",
    "            \n",
    "                \n",
    "    return Competency, A_count , Q_count, prob_test, ans_test, competencyPartial, probUser, userPuzzles, completedPartialData, probUserTest, ansUserTest, contPuzzlesUser\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(gamma, beta, output, totalData, train_set, test_set):\n",
    "    \n",
    "    \n",
    "    uDict,gDict,qDict,kcDict,kcsPuzzleDict = loadDataset(totalData)\n",
    "    competency_ELO = pd.DataFrame()\n",
    "    competency_ELO_PCA = pd.DataFrame()\n",
    "    difficulty_ELO = pd.DataFrame()    \n",
    "\n",
    "\n",
    "\n",
    "    # First stage\n",
    "    question_difficulty_array = dict() \n",
    "    question_counter_array = dict() \n",
    "\n",
    "\n",
    "    for q in qDict.keys():\n",
    "        if(q not in question_difficulty_array.keys()):\n",
    "            question_difficulty_array[q]=dict()\n",
    "            question_counter_array[q]=dict()\n",
    "            question_counter_array[q]=0\n",
    "\n",
    "        for k in kcDict.keys():\n",
    "            question_difficulty_array[q][k]=0   \n",
    "\n",
    "\n",
    "    learner_competency_array = dict() \n",
    "    response_counter_array = dict() \n",
    "    for user in uDict.keys():\n",
    "        if(user not in learner_competency_array.keys()):\n",
    "            learner_competency_array[user]=dict()\n",
    "            response_counter_array[user]=dict()\n",
    "            response_counter_array[user]=0\n",
    "        for k in kcDict.keys():\n",
    "            learner_competency_array[user][k]=0\n",
    "\n",
    "    # Array with the difficulty array        \n",
    "    arrayDiff = arrayDifficulty(totalData, learner_competency_array, question_difficulty_array, response_counter_array, question_counter_array, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "    puzzleDiffMean = dict()\n",
    "    #arrayDiffComp = dict()\n",
    "    #arrayDiffComp = arrayDiff\n",
    "    for puzzle in qDict.keys():\n",
    "        puzzleDiffMean[puzzle] = dict()\n",
    "        for k in kcsPuzzleDict[puzzle]:\n",
    "            puzzleDiffMean[puzzle][k] = 0\n",
    "            if(len(arrayDiff[puzzle][k]) > 30):\n",
    "                for i in range(10):\n",
    "                    arrayDiff[puzzle][k].pop(i)\n",
    "                    arrayDiff[puzzle][k].pop(-i)\n",
    "                    \n",
    "            puzzleDiffMean[puzzle][k] = statistics.mean(arrayDiff[puzzle][k])\n",
    "\n",
    "\n",
    "    # Second Stage\n",
    "    \n",
    "    if(output == 'metrics'):\n",
    "        \n",
    "        question_counter_Model = dict() \n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_counter_Model.keys()):\n",
    "                question_counter_Model[q]=dict()\n",
    "                question_counter_Model[q]=0\n",
    " \n",
    "\n",
    "\n",
    "        learner_competency_Model = dict() \n",
    "        response_counter_Model = dict()\n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency_Model.keys()):\n",
    "                learner_competency_Model[user]=dict()\n",
    "                response_counter_Model[user]=dict()\n",
    "                response_counter_Model[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency_Model[user][k]=0\n",
    "\n",
    "        learner_competency_train, response_counter_train, question_counter_train, prob_train, ans_train, competencyPartial_train, probUser_train, userPuzzles_train, completedPartialData, probUserTrain, ansUserTrain, contPuzzlesUser_Train = multiTopic_ELO(train_set, learner_competency_Model, puzzleDiffMean, response_counter_Model, question_counter_Model, kcsPuzzleDict,gDict,gamma, beta)\n",
    "        learner_competency_test ,response_counter_test, question_counter_test, prob_test, ans_test,competencyPartial_test, probUser_test, userPuzzles_test, completedPartialData, probUserT, ansUserT, contPuzzlesUser_Test = multiTopic_ELO(test_set, learner_competency_train, puzzleDiffMean, response_counter_train, question_counter_train, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "\n",
    "\n",
    "        # Quality metrics\n",
    "        group_prob_test = []\n",
    "        contUser =0\n",
    "        contT = 0\n",
    "        for user in prob_test.keys():\n",
    "            contUser+=1\n",
    "            for task in prob_test[user].keys():\n",
    "                contT+=1\n",
    "                group_prob_test.append(prob_test[user][task])\n",
    "\n",
    "        group_ans_test = []\n",
    "        for user in ans_test.keys():\n",
    "            for task in ans_test[user].keys():\n",
    "                group_ans_test.append(ans_test[user][task])        \n",
    "\n",
    "\n",
    "        accuracy = accuracyFunction(group_ans_test, group_prob_test)    \n",
    "        auc = auc_roc(group_ans_test, group_prob_test)\n",
    "        kappa = get_cohenKappa(group_ans_test, group_prob_test)\n",
    "\n",
    "        return accuracy, auc, kappa\n",
    "        \n",
    "        \n",
    "        \n",
    "    else: \n",
    "\n",
    "\n",
    "        # Data for step by step data output\n",
    "        question_counter = dict() \n",
    "\n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_counter.keys()):\n",
    "                question_counter[q]=dict()\n",
    "                question_counter[q]=0\n",
    "\n",
    "        learner_competency = dict() \n",
    "        response_counter = dict() \n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency.keys()):\n",
    "                learner_competency[user]=dict()\n",
    "                response_counter[user]=dict()\n",
    "                response_counter[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency[user][k]=0\n",
    "\n",
    "        # Multi-ELO function        \n",
    "        learner_competency_total, response_counter_total, question_counter_total, prob_total, ans_total, competencyPartial_total, probUser_total, userPuzzles_total, completedPartialData, probUserTest, ansUserTest, contPuzzlesUser = multiTopic_ELO(totalData, learner_competency, puzzleDiffMean, response_counter, question_counter, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "\n",
    "        totalCompetencyGMD = []\n",
    "        totalCompetencyCO5 = []\n",
    "        totalCompetencyCO6 = []\n",
    "        totalCompetencyMG1 = []\n",
    "\n",
    "\n",
    "        for user in learner_competency.keys():\n",
    "            for x in learner_competency[user]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    totalCompetencyGMD.append(learner_competency[user][x])\n",
    "                elif(x == 'CO.5'):\n",
    "                    totalCompetencyCO5.append(learner_competency[user][x]) \n",
    "                elif(x == 'CO.6'):\n",
    "                    totalCompetencyCO6.append(learner_competency[user][x])\n",
    "                elif(x == 'MG.1'):\n",
    "                    totalCompetencyMG1.append(learner_competency[user][x])    \n",
    "\n",
    "\n",
    "        minCompetencyGMD = min(totalCompetencyGMD)   \n",
    "        maxCompetencyGMD = max(totalCompetencyGMD)\n",
    "\n",
    "        minCompetencyCO5 = min(totalCompetencyCO5)   \n",
    "        maxCompetencyCO5 = max(totalCompetencyCO5)\n",
    "\n",
    "        minCompetencyCO6 = min(totalCompetencyCO6)   \n",
    "        maxCompetencyCO6 = max(totalCompetencyCO6)\n",
    "\n",
    "        minCompetencyMG1 = min(totalCompetencyMG1)   \n",
    "        maxCompetencyMG1 = max(totalCompetencyMG1)\n",
    "\n",
    "        normalized_learner_competency = dict()\n",
    "        normalized_global_competency = dict()\n",
    "        for user in learner_competency.keys():\n",
    "            normalized_learner_competency[user]=dict()\n",
    "            normalized_global_competency[user] = 0\n",
    "            for x in learner_competency[user]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyGMD)/(maxCompetencyGMD-minCompetencyGMD)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "                elif(x == 'CO.5'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO5)/(maxCompetencyCO5-minCompetencyCO5)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "                elif(x == 'CO.6'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO6)/(maxCompetencyCO6-minCompetencyCO6)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "                elif(x == 'MG.1'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyMG1)/(maxCompetencyMG1-minCompetencyMG1)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "\n",
    "        for user in normalized_global_competency.keys():\n",
    "            normalized_global_competency[user] = normalized_global_competency[user]/len(kcs)\n",
    "\n",
    "\n",
    "        # Normalization Difficulty    \n",
    "        totalDiffGMD = []\n",
    "        totalDiffCO5 = []\n",
    "        totalDiffCO6 = []\n",
    "        totalDiffMG1 = []\n",
    "\n",
    "        for puzzle in puzzleDiffMean.keys():\n",
    "            for x in puzzleDiffMean[puzzle]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    totalDiffGMD.append(puzzleDiffMean[puzzle][x])\n",
    "                elif(x == 'CO.5'):\n",
    "                    totalDiffCO5.append(puzzleDiffMean[puzzle][x]) \n",
    "                elif(x == 'CO.6'):\n",
    "                    totalDiffCO6.append(puzzleDiffMean[puzzle][x])\n",
    "                elif(x == 'MG.1'):\n",
    "                    totalDiffMG1.append(puzzleDiffMean[puzzle][x])    \n",
    "\n",
    "\n",
    "        minDiffGMD = min(totalDiffGMD)   \n",
    "        maxDiffGMD = max(totalDiffGMD)\n",
    "\n",
    "        minDiffCO5 = min(totalDiffCO5)   \n",
    "        maxDiffCO5 = max(totalDiffCO5)\n",
    "\n",
    "        minDiffCO6 = min(totalDiffCO6)   \n",
    "        maxDiffCO6 = max(totalDiffCO6)\n",
    "\n",
    "        minDiffMG1 = min(totalDiffMG1)   \n",
    "        maxDiffMG1 = max(totalDiffMG1)\n",
    "\n",
    "        normalized_question_difficulty = dict()\n",
    "\n",
    "        for puzzle in puzzleDiffMean.keys():\n",
    "            normalized_question_difficulty[puzzle]=dict()\n",
    "            for x in puzzleDiffMean[puzzle]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffGMD)/(maxDiffGMD-minDiffGMD)\n",
    "\n",
    "                elif(x == 'CO.5'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffCO5)/(maxDiffCO5-minDiffCO5)\n",
    "\n",
    "                elif(x == 'CO.6'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffCO6)/(maxDiffCO6-minDiffCO6)\n",
    "\n",
    "                elif(x == 'MG.1'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffMG1)/(maxDiffMG1-minDiffMG1)\n",
    "\n",
    "        if(output == 'step by step'):\n",
    "\n",
    "            for i in completedPartialData.keys():\n",
    "                    key_split = i.split('~')\n",
    "                    competency_ELO.at[i, 'group'] = gDict[key_split[0]]    \n",
    "                    competency_ELO.at[i, 'user'] = key_split[0] \n",
    "                    competency_ELO.at[i, 'task_id'] = key_split[1]\n",
    "                    competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "                    competency_ELO.at[i, 'final_kc_competency'] = round(normalized_learner_competency[key_split[0]][key_split[2]],3)\n",
    "                    competency_ELO.at[i, 'final_global_competency'] = round(normalized_global_competency[key_split[0]],3)\n",
    "                    competency_ELO.at[i, 'current_competency'] = key_split[3]\n",
    "                    competency_ELO.at[i, 'probability'] = round(completedPartialData[i]['prob'],3)\n",
    "                    competency_ELO.at[i, 'correct'] = completedPartialData[i]['correct']\n",
    "                    competency_ELO.at[i, 'kcs_importance'] = round(completedPartialData[i]['kcs importance'],3)\n",
    "                    competency_ELO.at[i, 'difficulty'] = round(puzzleDiffMean[key_split[1]][key_split[2]],3)\n",
    "                    competency_ELO.at[i, 'weight_att'] = round(completedPartialData[i]['Weight'],3)\n",
    "                    competency_ELO.at[i, 'timestamp'] = completedPartialData[i]['timestamp']\n",
    "                    if(len(ansUserTest[key_split[0]]) > 0): competency_ELO.at[i, 'accuracy'] = str(round(accuracyFunction(ansUserTest[key_split[0]], probUserTest[key_split[0]]), 3)) \n",
    "                    else: competency_ELO.at[i, 'accuracy'] = str(np.nan)                    \n",
    "                    competency_ELO.at[i, 'n_puzzles_attempted'] = len(contPuzzlesUser[key_split[0]])\n",
    "                    competency_ELO.at[i, 'p_attempted'] = round((len(contPuzzlesUser[key_split[0]]) * 100)/((len(intermediatePuzzles) + len(advancedPuzzles))-1), 3)\n",
    "                    competency_ELO.at[i, 'change_competency'] = round(completedPartialData[i]['changeComp'],3)\n",
    "                    competency_ELO.at[i, 'complete_change_comp'] = round(completedPartialData[i]['complete_change_comp'],3)\n",
    "                    #competency_ELO.at[i, 'change_difficulty'] = round(completedPartialData[i]['changeDiff'],3)\n",
    "\n",
    "            #data output preparation  \n",
    "            competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','task_id', 'timestamp','kc','kcs_importance','final_kc_competency', 'final_global_competency','current_competency','change_competency','weight_att','complete_change_comp', 'probability', 'correct','accuracy','n_puzzles_attempted','p_attempted', 'difficulty'])\n",
    "\n",
    "            return competency_ELO\n",
    "\n",
    "        \n",
    "        if(output == 'standard'): \n",
    "            \n",
    "            # Data for final data output (difficulty)\n",
    "            concatedTaskKc = dict()\n",
    "\n",
    "            for q in qDict.keys():\n",
    "                for k in kcsPuzzleDict[q].keys():\n",
    "                    concatedTaskKc[q+'~'+k] = 0\n",
    "                    \n",
    "\n",
    "            for i in concatedTaskKc.keys():\n",
    "                key_split = i.split('~')\n",
    "                difficulty_ELO.at[i, 'task_id'] = key_split[0]\n",
    "                difficulty_ELO.at[i, 'kc'] = key_split[1]\n",
    "                difficulty_ELO.at[i, 'difficulty'] = round(puzzleDiffMean[key_split[0]][key_split[1]],3)  \n",
    "                difficulty_ELO.at[i, 'normalized_difficulty'] = round(normalized_question_difficulty[key_split[0]][key_split[1]],3)               \n",
    "\n",
    "\n",
    "\n",
    "            idComplet = dict()\n",
    "            for g in gDict.values():\n",
    "                for u in gDict.keys():\n",
    "                    for k in kcs:\n",
    "                        iCom = g+'~'+u+'~'+k\n",
    "                        idComplet[iCom] = 0\n",
    "\n",
    "            for i in idComplet.keys():\n",
    "                key_split = i.split('~')\n",
    "                competency_ELO.at[i, 'group'] = key_split[0]    \n",
    "                competency_ELO.at[i, 'user'] = key_split[1]    \n",
    "                competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "                competency_ELO.at[i, 'competency'] = round(normalized_learner_competency[key_split[1]][key_split[2]],3) \n",
    "                if(len(ansUserTest[key_split[1]]) > 0): competency_ELO_PCA.at[i, 'accuracy'] = str(round(accuracyFunction(ansUserTest[key_split[1]], probUserTest[key_split[1]]), 3)) \n",
    "                else: competency_ELO_PCA.at[i, 'accuracy'] = np.nan\n",
    "                if(len(ansUserTest[key_split[1]]) > 0): competency_ELO.at[i, 'accuracy'] = str(round(accuracyFunction(ansUserTest[key_split[1]], probUserTest[key_split[1]]), 3)) \n",
    "                else: competency_ELO.at[i, 'accuracy'] = str(np.nan)\n",
    "                competency_ELO.at[i, 'n_puzzles_attempted'] = len(contPuzzlesUser[key_split[1]])\n",
    "                competency_ELO_PCA.at[i, 'n_puzzles_attempted'] = len(contPuzzlesUser[key_split[1]])\n",
    "                competency_ELO.at[i, 'p_attempted'] = round((len(contPuzzlesUser[key_split[1]]) * 100)/((len(intermediatePuzzles) + len(advancedPuzzles))-1), 3)\n",
    "            \n",
    "            # Replace NaN values by 0\n",
    "            competency_ELO_PCA['accuracy'] = competency_ELO_PCA['accuracy'].replace(np.nan, 0)\n",
    "            # Data preprocesing to match variable weights\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(competency_ELO_PCA)\n",
    "            scaled_data = scaler.transform(competency_ELO_PCA)\n",
    "            \n",
    "            # PCA object and look for the main variables\n",
    "            pca = PCA(n_components=1)\n",
    "            pca.fit(scaled_data)\n",
    "            # Dimensionality reduction\n",
    "            x_pca = pca.transform(scaled_data)\n",
    "            \n",
    "            # Re-enter the NaN values\n",
    "            x_pca = np.round(np.where(x_pca == min(x_pca), np.nan, x_pca),3)\n",
    "            \n",
    "            # Normalized\n",
    "            x_pca_normalized = np.round(normalized_PCA(x_pca),3)\n",
    "            \n",
    "            #data output preparation  \n",
    "            difficulty_ELO = pd.DataFrame(difficulty_ELO, columns = ['task_id','kc', 'difficulty','normalized_difficulty'])\n",
    "            competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','kc', 'competency', 'accuracy','n_puzzles_attempted','p_attempted'])\n",
    "            \n",
    "\n",
    "            competency_ELO['pca'] = x_pca.astype(str)\n",
    "            competency_ELO['pca_normalized'] = x_pca_normalized.astype(str)\n",
    "            \n",
    "            \n",
    "            return competency_ELO, difficulty_ELO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalData, train_set, test_set = adaptedData(dataEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "competency_ELO, difficulty_ELO= run(1.8, 0.05, 'standard', totalData, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>user</th>\n",
       "      <th>kc</th>\n",
       "      <th>competency</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>n_puzzles_attempted</th>\n",
       "      <th>p_attempted</th>\n",
       "      <th>pca</th>\n",
       "      <th>pca_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd~56ccce25ead834182d605eff319bfa2c~GMD.4</td>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd</td>\n",
       "      <td>56ccce25ead834182d605eff319bfa2c</td>\n",
       "      <td>GMD.4</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.857</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.545</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd~56ccce25ead834182d605eff319bfa2c~CO.5</td>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd</td>\n",
       "      <td>56ccce25ead834182d605eff319bfa2c</td>\n",
       "      <td>CO.5</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.857</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.545</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd~56ccce25ead834182d605eff319bfa2c~CO.6</td>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd</td>\n",
       "      <td>56ccce25ead834182d605eff319bfa2c</td>\n",
       "      <td>CO.6</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.857</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.545</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd~56ccce25ead834182d605eff319bfa2c~MG.1</td>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd</td>\n",
       "      <td>56ccce25ead834182d605eff319bfa2c</td>\n",
       "      <td>MG.1</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.857</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.545</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f3a762d65030a131dd2~GMD.4</td>\n",
       "      <td>cb71040b5bd1341a34afc24961536ebd</td>\n",
       "      <td>476c86cda40e6f3a762d65030a131dd2</td>\n",
       "      <td>GMD.4</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.625</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.273</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061~fb504c1409250aaef610c9d9b7306e18~MG.1</td>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061</td>\n",
       "      <td>fb504c1409250aaef610c9d9b7306e18</td>\n",
       "      <td>MG.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c8816d80129f875b351~GMD.4</td>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061</td>\n",
       "      <td>5cce64bf55190c8816d80129f875b351</td>\n",
       "      <td>GMD.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c8816d80129f875b351~CO.5</td>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061</td>\n",
       "      <td>5cce64bf55190c8816d80129f875b351</td>\n",
       "      <td>CO.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c8816d80129f875b351~CO.6</td>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061</td>\n",
       "      <td>5cce64bf55190c8816d80129f875b351</td>\n",
       "      <td>CO.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c8816d80129f875b351~MG.1</td>\n",
       "      <td>e21640b4aea9349ad77d86d6017cb061</td>\n",
       "      <td>5cce64bf55190c8816d80129f875b351</td>\n",
       "      <td>MG.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9216 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               group  \\\n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  cb71040b5bd1341a34afc24961536ebd   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  cb71040b5bd1341a34afc24961536ebd   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  cb71040b5bd1341a34afc24961536ebd   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  cb71040b5bd1341a34afc24961536ebd   \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...  cb71040b5bd1341a34afc24961536ebd   \n",
       "...                                                                              ...   \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...  e21640b4aea9349ad77d86d6017cb061   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  e21640b4aea9349ad77d86d6017cb061   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  e21640b4aea9349ad77d86d6017cb061   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  e21640b4aea9349ad77d86d6017cb061   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  e21640b4aea9349ad77d86d6017cb061   \n",
       "\n",
       "                                                                                user  \\\n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  56ccce25ead834182d605eff319bfa2c   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  56ccce25ead834182d605eff319bfa2c   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  56ccce25ead834182d605eff319bfa2c   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  56ccce25ead834182d605eff319bfa2c   \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...  476c86cda40e6f3a762d65030a131dd2   \n",
       "...                                                                              ...   \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...  fb504c1409250aaef610c9d9b7306e18   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  5cce64bf55190c8816d80129f875b351   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  5cce64bf55190c8816d80129f875b351   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  5cce64bf55190c8816d80129f875b351   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  5cce64bf55190c8816d80129f875b351   \n",
       "\n",
       "                                                       kc  competency  \\\n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...  GMD.4       0.555   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...   CO.5       0.605   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...   CO.6       0.604   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...   MG.1       0.470   \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...  GMD.4       0.169   \n",
       "...                                                   ...         ...   \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...   MG.1       0.000   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...  GMD.4       0.000   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...   CO.5       0.000   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...   CO.6       0.000   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...   MG.1       0.000   \n",
       "\n",
       "                                                   accuracy  \\\n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...    0.857   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...    0.857   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...    0.857   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...    0.857   \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...    0.625   \n",
       "...                                                     ...   \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...      nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...      nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...      nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...      nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...      nan   \n",
       "\n",
       "                                                    n_puzzles_attempted  \\\n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...                 12.0   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...                 12.0   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...                 12.0   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...                 12.0   \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...                  6.0   \n",
       "...                                                                 ...   \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...                  0.0   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...                  0.0   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...                  0.0   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...                  0.0   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...                  0.0   \n",
       "\n",
       "                                                    p_attempted    pca  \\\n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...       54.545  1.037   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...       54.545  1.037   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...       54.545  1.037   \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...       54.545  1.037   \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...       27.273  0.047   \n",
       "...                                                         ...    ...   \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...        0.000    nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...        0.000    nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...        0.000    nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...        0.000    nan   \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...        0.000    nan   \n",
       "\n",
       "                                                   pca_normalized  \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...          0.693  \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...          0.693  \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...          0.693  \n",
       "cb71040b5bd1341a34afc24961536ebd~56ccce25ead834...          0.693  \n",
       "cb71040b5bd1341a34afc24961536ebd~476c86cda40e6f...          0.424  \n",
       "...                                                           ...  \n",
       "e21640b4aea9349ad77d86d6017cb061~fb504c1409250a...            nan  \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...            nan  \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...            nan  \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...            nan  \n",
       "e21640b4aea9349ad77d86d6017cb061~5cce64bf55190c...            nan  \n",
       "\n",
       "[9216 rows x 9 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competency_ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
